<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="FIORD is a fisheye indoor-outdoor dataset for 3D scene reconstruction purposes.">
  <meta name="keywords" content="Fisheye, Gaussian Splatting, NeRF, Indoor, Outdoor">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D Scene Reconstruction and Benchmarking</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <script type="module" src="https://unpkg.com/@google/model-viewer/dist/model-viewer.min.js"></script>
<!-- CSS -->
<link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css">

<!-- JS (确保先加载了jQuery，因为Bootstrap的JS依赖于jQuery) -->
<script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js"></script>


<link rel="stylesheet" href="https://cdn.knightlab.com/libs/juxtapose/latest/css/juxtapose.css">
<script src="https://cdn.knightlab.com/libs/juxtapose/latest/js/juxtapose.min.js"></script>

  
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D Scene Reconstruction and Benchmarking</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a>Ulas Gunes</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://maturk.github.io/">Matias Turkulainen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://xuqianren.github.io/">Xuqian Ren</a><sup>1</sup>,
            </span>
            <span class="author-block">
              <a href="https://users.aalto.fi/~asolin/">Arno Solin</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://users.aalto.fi/~kannalj1/">Juho Kannala</a><sup>2</sup>,
            </span>
            <span class="author-block">
              <a href="https://esa.rahtu.fi/">Esa Rahtu</a><sup>1</sup>,
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Tampere University</span>
            <span class="author-block"><sup>2</sup>Aalto University</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2011.12948"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- 
              <span class="link-block">
                <a href="https://github.com/google/nerfies"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
            -->
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://github.com/google/nerfies/releases/tag/0.1"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Data</span>
                  </a>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            The development of large-scale 3D scene reconstruction and
            novel view synthesis methods mostly rely on datasets comprising per
           spective images with narrow fields of view (FoV). While effective for
            small-scale scenes, these datasets require large image sets and extensive
            structure-from-motion (SfM) processing, limiting scalability. To address
            this, we introduce a fisheye image dataset tailored for scene reconstruction tasks. Using dual 200-degree fisheye lenses, our dataset provides full
            360-degree coverage of 5 indoor and 5 outdoor scenes. Each scene has
            sparse SfM point clouds and precise LIDAR-derived dense point clouds
            that can be used as geometric ground-truth, enabling robust benchmarking under challenging conditions such as occlusions and reflections. While
            the baseline experiments focus on vanilla Gaussian Splatting and NeRF
            based Nerfacto methods, the dataset supports diverse approaches for
            scene reconstruction, novel view synthesis, and image-based rendering.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
  </div>
</section>

<section id="dataset-overview" class="section">
  <div class="container">
    <h2 class="title">Dataset Overview</h2>
    
    <figure class="image is-3by2">
      <img src="./static/images/dataset_overview.jpg" alt="Overview of dataset environments">
    </figure>

    <p>
      Our dataset contains still fisheye images of 5 indoor and 5 outdoor environments, captured using an Insta360 RS-One Inch camera. Each scene includes both sparse point clouds (via Structure-from-Motion) and dense LIDAR scans.
    </p>

    <!-- NEW IMAGE PREVIEW -->
    <figure class="image is-3by2" style="margin-top: 2rem;">
      <img src="./static/images/pointcloud_preview.jpg" alt="Point cloud preview">
      <figcaption class="has-text-centered">Example point cloud visualizations from our dataset</figcaption>
    </figure>
    
  </div>
</section>



<section id="data-capture-process" class="section">
  <div class="container">
    <h2 class="title">Data Capturing</h2>
    
    <!-- First Row: Data Capture -->
    <div class="content">
      <figure class="image">
        <img src="./static/images/pres2-1(2).png" alt="Data Capture">
        <img src="./static/images/IMG_20241218_180016_00_967.jpeg" alt="Data Processing">
      </figure>
      <p>
        The Insta360 camera was mounted on a tripod, and placed at a fixed
        location to take a single shot for the scene image capturing process. Afterwards, it was repositioned
        with minimal rotation and movement (less than 10 cm between each camera
        positioning and less than 60 degrees of rotation to either side on the lateral axis of
        the camera) to another location within the scene, and another image was taken.
        This process was repeated systematically until the entire scene was covered,
        with each lens consistently covering the same side of the scene at all times.
        This consistency, combined with the minimal rotation or movement between
        each capture ensured sufficient overlap between the images, which played a key
        role in the subsequent accurate SfM based sparse point cloud generation step.
      </p>
      <p>To avoid disruptions from moving objects, such as people in indoor environ-
        ments or cars in outdoor settings, images were captured at times and locations
        with minimal activity. The photographer ensured they remained out of the frame
        by strategically positioning themselves in occluded areas or sequentially capturing the two fisheye images from the same fixed position—first taking a shot while
        remaining outside the field of view (FoV) of one lens, then repositioning to avoid
        the FoV of the second lens before capturing the next image.
      </p>
      <p>
       Faro Focus 3D LIDAR scanner, fixed on a tripod is also used to capture high-resolution XYZRGB dense point clouds, which can be used as geometric ground truths for the scenes we captured.
      This ground truth information can be used for point cloud alignment, 3D scene reconstruction and novel view synthesis model benchmarking and accuracy validation purposes. Scene reconstruction methods that incorporate depth information can also find these dense point clouds useful.
      </p>
    </div>
    
  </div>
</section>

<section id="data-processing" class="section">
  <div class="container">
    <h2 class="title">Data Processing</h2>
    <div class="content">
      <figure class="image">
        <img src="./static/images/Presentation-6-1-1.png" alt="Data Flow">
      </figure>
      <p class="justified-text">
        For each scene, Insta360 camera is used to obtain still fisheye images and the Faro scanner is used to capture the dense 3D point cloud for geometry reference. Prior to image capture, the two fisheye cameras of the Insta360 camera are calibrated and the estimated calibration parameters are fed to COLMAP, along with the still fisheye images, to create sparse point clouds of our scenes. 
        The sparse point cloud generated by the Structure-from-Motion pipeline COLMAP is then aligned with the dense 3D point cloud obtained from the LIDAR scanner to enable
        direct comparison and evaluation for downstream applications of 3D scene reconstruction methods.
        
      </p>
    </div>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{gunes2025fiord,
  author    = {Gunes, Ulas and Turkulainen, Matias and Ren, Xuqian and Solin, Arno and Kannala, Juho and Rahtu, Esa},
  title     = {FIORD: A Fisheye Indoor-Outdoor Dataset with LIDAR Ground Truth for 3D Scene Reconstruction and Benchmarking},
  journal   = {},
  year      = {2025},
}</code></pre>
  </div>
</section>



<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="https://github.com/nerfies/nerfies.github.io">source code</a> of this website,
            we just ask that you link back to this page in the footer.
            Please remember to remove the analytics code included in the header of the website which
            you do not want on your website.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
